{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd82a1c-262f-473b-9e67-6b7864b1f7de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader, WeightedRandomSampler\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms, models\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_image\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfolder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_loader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from torchvision.io import read_image\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55263b5b-3909-4472-a419-c07ec178c766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Depaul\\DATA_SCIENCE\\prog_ml_apps\\DATASET\\archive (5)\n"
     ]
    }
   ],
   "source": [
    "cd \"D:\\Depaul\\DATA_SCIENCE\\prog_ml_apps\\DATASET\\archive (5)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c45db5d-f010-40ed-92f6-e10f27eeee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('Data_Entry_2017.csv')\n",
    "my_glob = glob('images*/images/*.png')\n",
    "all_image_paths = {os.path.basename(x): x for x in my_glob}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5363670-e647-4991-8572-8a182509160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scans found:', len(all_image_paths), ', Total Headers', data.shape[0])\n",
    "data['path'] = data['Image Index'].map(all_image_paths.get)\n",
    "data['Patient Age'] = data['Patient Age'].map(lambda x: int(x[:-1]) if isinstance(x, str) else x)\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58b284-3793-4e7a-baab-41c9fba9fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process labels\n",
    "data['Finding Labels'] = data['Finding Labels'].map(lambda x: x.replace('No Finding', '') if pd.notnull(x) else '')\n",
    "all_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x) > 0]\n",
    "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
    "for c_label in all_labels:\n",
    "    if len(c_label) > 1:\n",
    "        data[c_label] = data['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5618c71-7bbc-4ed2-834d-8495aac740ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter labels\n",
    "MIN_CASES = 1000\n",
    "all_labels = ['Effusion', 'Infiltration', 'Mass', 'Nodule', 'Atelectasis', 'Pneumothorax']\n",
    "print('Clean Labels ({})'.format(len(all_labels)), [(c_label, int(data[c_label].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f963b40-5a22-4840-859f-eb8767f37f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "columns_to_drop = ['Follow-up #', 'Patient ID', 'Patient Age', 'Patient Gender', 'View Position', \n",
    "                   'OriginalImage[Width', 'Height]', 'OriginalImagePixelSpacing[x', 'y]', 'Unnamed: 11']\n",
    "data = data.drop(columns=[col for col in columns_to_drop if col in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa2e9be-5965-4bf1-9d5d-b66f435d7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create disease vector\n",
    "data['disease_vec'] = data.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])\n",
    "\n",
    "counts = data['Finding Labels'].value_counts()\n",
    "mask = data['Finding Labels'].isin(counts[counts >= 251].index)\n",
    "data = data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99576b-f72f-4d6e-bbc1-8d891e9c6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter patients with exactly one disease\n",
    "data['Total Diseases'] = data[all_labels].sum(axis=1)\n",
    "data_one_disease = data[data['Total Diseases'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93081ffa-eaf0-427f-b9b6-9e2f4686ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling 5 images per class\n",
    "def sample_images_per_class(data, class_labels, num_samples=5):\n",
    "    sampled_data = pd.DataFrame()\n",
    "    for label in class_labels:\n",
    "        sampled_data = sampled_data.append(data[data[label] == 1].sample(num_samples, random_state=123))\n",
    "    return sampled_data\n",
    "\n",
    "sampled_data = sample_images_per_class(data_one_disease, all_labels, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3164e5e-ed5f-40f7-bc6a-1731d434dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(sampled_data, test_size=0.2, random_state=123)\n",
    "print('train', train_df.shape[0], 'validation', valid_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77741801-3b75-4dd6-9a4b-1c78b937db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "IMG_SIZE = (128, 128)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cf551-6669-4e8c-81f5-994da32d2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['path']\n",
    "        image = default_loader(img_path)\n",
    "        label = self.dataframe.iloc[idx][all_labels].values.astype(np.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaa215-d278-4840-9ac7-300e6aba42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ChestXrayDataset(train_df, transform=train_transforms)\n",
    "valid_dataset = ChestXrayDataset(valid_df, transform=valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c3870-0c87-4a94-88c1-16858fe3def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=256, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b05a1-2b12-46d5-ac6f-f1c07d727158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class CustomDenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomDenseNet121, self).__init__()\n",
    "        self.base_model = models.densenet121(pretrained=True)\n",
    "        self.base_model.classifier = nn.Identity()  # Remove the original classifier\n",
    "        self.dense_block = nn.Sequential(\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024, 32, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(1056),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1056, 32, kernel_size=3, padding='same'),\n",
    "        )\n",
    "        self.transition_block = nn.Sequential(\n",
    "            nn.BatchNorm2d(1088),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1088, 128, kernel_size=1, padding='same'),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)\n",
    "        x = self.dense_block(x)\n",
    "        x = self.transition_block(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefec3a7-9810-4234-a30c-f03dfeb49eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, loss, and optimizer\n",
    "model = CustomDenseNet121(num_classes=len(all_labels)).to('cuda')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc16c600-6ae4-4e52-8438-f35dcdc4a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "best_loss = float('inf')\n",
    "early_stopping_patience = 3\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    val_loss /= len(valid_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "    \n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67f2e5-a7fe-4f98-be9c-4eb1c942f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in valid_loader:\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910f35e-f579-41fd-bf14-4cdae93199aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665d78d-6dd0-4685-8f79-3f16ad600ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ROC Curves\n",
    "fig, c_ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "for (idx, c_label) in enumerate(all_labels):\n",
    "    fpr, tpr, _ = roc_curve(all_labels[:, idx].astype(int), all_preds[:, idx])\n",
    "    c_ax.plot(fpr, tpr, label='%s (AUC:%0.2f)' % (c_label, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be0e91-043e-48e7-86da-aa4fe3486fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec2b8d-97ae-428b-a0fb-2ed4d63f16fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae5caa2-6f19-4d30-a23d-e1be7c1e4cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa314a64-887c-4114-97f9-c71464153ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
